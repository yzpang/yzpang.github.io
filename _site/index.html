<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.13.0 by Michael Rose
  Copyright 2013-2018 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE.txt
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Yuanzhe (Richard) Pang</title>
<meta name="description" content="Richard’s website">



<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Yuanzhe (Richard) Pang">
<meta property="og:title" content="Yuanzhe (Richard) Pang">
<meta property="og:url" content="http://localhost:4000/">












  

  


<link rel="canonical" href="http://localhost:4000/">







  <script type="application/ld+json">
    {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "Yuanzhe (Richard) Pang",
      "url": "http://localhost:4000",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Yuanzhe (Richard) Pang Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--home">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="/">Yuanzhe (Richard) Pang</a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/research/" >Research</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="http://schema.org/Person">

  
    <div class="author__avatar">
      

      
        <img src="/_pages/images/me.jpg" alt="" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name"></h3>
    
    
  </div>

  <div class="author__urls-wrapper">
    <!-- <button class="btn btn--inverse">Follow</button> -->
    <ul class="author__urls social-icons">
      

      

      



      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <div class="archive">
    
      <h1 id="page-title" class="page__title"></h1>
    
    

<!-- <h3 class="archive__subtitle">Recent posts</h3> -->

<html>
<head>
<style>
p.xsmall {
    line-height: 1.55;
    font-size: 9.5pt;
    margin-left: 40px; 
}

p.small {
    line-height: 1.55;
    font-size: 11pt;
    margin-left: 40px; 
}

ul.small {
    line-height: 1.55;
    font-size: 11pt;
}

p.small2 {
    line-height: 2.00;
    font-size: 11.5pt;
    margin-left: 40px; 
}

p.medium {
    line-height: 1.55;
    font-size: 12.5pt;
    margin-left: 40px; 
}

p.big {
    line-height: 1.55;
}

p.noindent {
    line-height: 1.55;
    font-size: 12pt;
}


</style>
</head>
<body>









<p class="noindent">

Hello. I am a computer science Ph.D. candidate at the Courant Institute of Mathematical Sciences at New York University. I am a member of the <a href="https://wp.nyu.edu/ml2/people/" style="color: #57068C; text-decoration: none" target="_blank">Machine Learning for Language (ML²) group</a> (subset of the <a href="https://wp.nyu.edu/cilvr/" style="color: #57068C; text-decoration: none" target="_blank">CILVR group</a>). I am advised by Profs. <a href="https://hhexiy.github.io" style="color: #757575; text-decoration: none" target="_blank">He He</a> and <a href="http://www.kyunghyuncho.me" style="color: #757575; text-decoration: none" target="_blank">Kyunghyun Cho</a>. I also frequently collaborate with Prof. <a href="https://cims.nyu.edu/~sbowman/" style="color: #757575; text-decoration: none" target="_blank">Sam Bowman</a>. Since October 2022, I have been a Visiting Researcher at Meta AI (FAIR), mentored by Drs. <a href="https://scholar.google.com/citations?hl=en&user=lMkTx0EAAAAJ" style="color: #757575; text-decoration: none" target="_blank">Jason Weston</a> and formerly <a href="https://stephenroller.com/" style="color: #757575; text-decoration: none" target="_blank">Stephen Roller</a>. 

<br><br>

My research focuses on natural langauge processing and machine learning. Specifically, my recent interests include text generation (learning from reward, learning from feedback, machine translation, dialogue, decoding, uncertainty, etc.), long-text understanding, and reasoning. 

<br><br>

Prior to my Ph.D., I graduated from the University of Chicago (B.S. in mathematics and B.S. in computer science). At Toyota Technological Institute at Chicago (TTIC) and the University of Chicago, I worked on text generation and structured prediction with my advisor Prof. <a href="http://ttic.uchicago.edu/~kgimpel/" style="color: #757575; text-decoration: none" target="_blank">Kevin Gimpel</a>. In Summer 2020, I was a Research Intern at Google Research New York and worked on summarization; in Summer 2021, I was a Research Intern at Google Brain and investigated efficient pretraining. 

</font>
<p>











<h3 style="font-weight: 500">Research</h3>





<p class="small">
<!-- </font> -->
<span style="line-height:170%"> 
<i>Primary</i> research subfields: <a style="color: #245ED2; text-decoration: none">text generation</a> (including <a style="color: #753DA4; text-decoration: none">machine translation</a>), <a style="color: #0A897D; text-decoration: none">structured prediction</a>, <a style="color: #22789D; text-decoration: none">language understanding</a>, <a style="color: #5c9e82; text-decoration: none">pretraining</a>, and <a style="color: #757575; text-decoration: none">others</a>. 
[<a href="https://www.semanticscholar.org/author/Richard-Yuanzhe-Pang/46230016" style="color: #4C8BF5; text-decoration: none" target="_blank">semantic scholar</a>] [<a href="https://scholar.google.com/citations?hl=en&user=vg_IkckAAAAJ" style="color: #4C8BF5; text-decoration: none" target="_blank">google scholar</a>] [<a href="https://dblp.org/pid/250/9059.html" style="color: #4C8BF5; text-decoration: none" target="_blank">dblp</a>] [<a href="../misc-files/abbreviations.txt" style="color: #4C8BF5; text-decoration: none" target="_blank">abbreviations</a>]
</span>


<br>

<hr>


<!-- <p class="small">
<span style="line-height:170%"> <u> Preprints </u> </span>







<br><br>
 -->



<!-- 
<p class="small">
<span style="line-height:170%"> <u> Preprints </u> </span>

 -->




<p class="small">
<span style="line-height:170%"> <u> Publications and preprints (2023-) </u> </span>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2303.04562" style="font-size: 12pt; color: #245ED2; text-decoration: none"> Extrapolative Controlled Sequence Generation via Iterative Refinement </a> <br> </span>
<span style="line-height:170%"> Vishakh Padmakumar, Richard Yuanzhe Pang, He He, Ankur P. Parikh </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of ICML 2023</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2303.04562.pdf" style="color: #245ED2; text-decoration: none">paper</a>] [<a href="./research/#exactline-ice" style="color: #245ED2; text-decoration: none">abstract</a>] [<a href="../misc-files/bibs/padmakumar2023extrapolative.txt" style="color: #245ED2; text-decoration: none">bibtex</a>]
</span>


<br>
<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2211.08714" style="font-size: 12pt; color: #245ED2; text-decoration: none"> Reward Gaming in Conditional Text Generation </a> <br> </span>
<span style="line-height:170%"> Richard Yuanzhe Pang, Vishakh Padmakumar, Thibault Sellam, Ankur P. Parikh, He He </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of ACL 2023</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2211.08714.pdf" style="color: #245ED2; text-decoration: none">paper</a>] [<a href="./research/#exactline-gaming" style="color: #245ED2; text-decoration: none">abstract</a>] [<a href="../misc-files/bibs/pang2022reward.txt" style="color: #245ED2; text-decoration: none">bibtex</a>]
</span>


<br>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2208.12852" style="font-size: 12pt; color: #757575; text-decoration: none"> What Do NLP Researchers Believe? Results of the NLP Community Metasurvey </a> <br> </span>
<span style="line-height:170%"> Julian Michael, Ari Holtzman, Alicia Parrish, Aaron Mueller, Alex
 Wang, Angelica Chen, Divyam Madaan, Nikita Nangia, Richard Yuanzhe Pang, Jason Phang, Samuel R. Bowman </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of ACL 2023</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2208.12852.pdf" style="color: #757575; text-decoration: none">paper</a>] [<a href="./research/#exactline-survey" style="color: #757575; text-decoration: none">abstract</a>] [<a href="https://nlpsurvey.net/" style="color: #757575; text-decoration: none">website</a>] [<a href="../misc-files/links/survey-articles.html" style="color: #757575; text-decoration: none">press</a>] [<a href="../misc-files/bibs/michael2022nlp.txt" style="color: #757575; text-decoration: none">bibtex</a>]</span>


<br>


<p class="small">
<span style="line-height:170%"> <u> Publications (2021-2022)</u> — main focus: text generation (learning from rewards, RL), long-document understanding (question answering, summarization) </span>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2205.11465" style="font-size: 12pt; color: #245ED2; text-decoration: none"> SQuALITY: Building a Long-Document Summarization Dataset the Hard Way </a> <br> </span>
<span style="line-height:170%"> Alex Wang, Richard Yuanzhe Pang, Angelica Chen, Jason Phang, Samuel R. Bowman </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of EMNLP 2022</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2205.11465.pdf" style="color: #245ED2; text-decoration: none">paper</a>] [<a href="./research/#exactline-squality" style="color: #245ED2; text-decoration: none">abstract</a>] [<a href="https://github.com/nyu-mll/SQuALITY/tree/main/data" style="color: #245ED2; text-decoration: none">data</a>] [<a href="https://github.com/nyu-mll/SQuALITY" style="color: #245ED2; text-decoration: none">code</a>] [<a href="../misc-files/bibs/wang2022squality.txt" style="color: #245ED2; text-decoration: none">bibtex</a>]
</span>


<br>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2112.08670" style="font-size: 12pt; color: #753DA4; text-decoration: none"> Amortized Noisy Channel Neural Machine Translation </a> <br> </span>
<span style="line-height:170%"> Richard Yuanzhe Pang, He He, Kyunghyun Cho </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of INLG 2022</i>; best presentation award</span>
<br>
<span style="line-height:195%; font-size: 9pt"> tl;dr: amortizing the inference cost of "beam search and rerank" – learning to rerank without explicitly reranking </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2112.08670.pdf" style="color: #753DA4; text-decoration: none">paper</a>] [<a href="./research/#exactline-amortized-noisy-channel" style="color: #753DA4; text-decoration: none">abstract</a>] [<a href="https://www.youtube.com/watch?v=EqpNw7JJvI4" style="color: #753DA4; text-decoration: none">talk</a>] [<a href="../misc-files/pang+etal-amortized-poster-inlg2022.pdf" style="color: #753DA4; text-decoration: none">poster</a>] [<a href="../misc-files/bibs/pang2021amortized.txt" style="color: #753DA4; text-decoration: none">bibtex</a>]</span>



<br>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2112.08608" style="font-size: 12pt; color: #22789D; text-decoration: none"> QuALITY: Question Answering with Long Input Texts, Yes! </a> <br> </span>
<span style="line-height:160%"> Richard Yuanzhe Pang<sup>*</sup>, Alicia Parrish<sup>*</sup>, Nitish Joshi<sup>*</sup>, Nikita Nangia, Jason Phang, Angelica Chen, Vishakh Padmakumar, Johnny Ma, Jana Thompson, He He, Samuel R. Bowman </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of NAACL 2022</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2112.08608.pdf" style="color: #22789D; text-decoration: none">paper</a>] [<a href="./research/#exactline-quality" style="color: #22789D; text-decoration: none">abstract</a>] [<a href="https://github.com/nyu-mll/quality/tree/main/data" style="color: #22789D; text-decoration: none">data</a>] [<a href="https://github.com/nyu-mll/quality/tree/main/baselines" style="color: #22789D; text-decoration: none">code</a>] [<a href="https://nyu-mll.github.io/quality/" style="color: #22789D; text-decoration: none">leaderboard</a>] [<a href="https://www.youtube.com/watch?v=WAhSW5iP8iw" style="color: #22789D; text-decoration: none">15-min live talk</a>] [<a href="../misc-files/pang+etal-quality-slides-naacl2022.pdf" style="color: #22789D; text-decoration: none">slides</a>] [<a href="../misc-files/bibs/pang2022quality.txt" style="color: #22789D; text-decoration: none">bibtex</a>] | by others: [<a href="https://www.tensorflow.org/datasets/catalog/quality" style="color: #22789D; text-decoration: none">tfds</a>] [<a href="https://www.metaculus.com/questions/9628/question-answering-on-long-texts-by-2025/" style="color: #22789D; text-decoration: none">forecast</a>] [<a href="https://www.science.org/content/article/computers-ace-iq-tests-still-make-dumb-mistakes-can-different-tests-help" style="color: #22789D; text-decoration: none">press mention by <i>Science</i></a>] [<a href="https://www.scrolls-benchmark.com/" style="color: #22789D; text-decoration: none">scrolls</a>]</span>


<br>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2203.13240" style="font-size: 12pt; color: #5c9e82; text-decoration: none"> Token Dropping for Efficient BERT Pretraining </a> <br> </span>
<span style="line-height:170%"> Le Hou<sup>*</sup>, Richard Yuanzhe Pang<sup>*</sup>, Tianyi Zhou, Yuexin Wu, Xinying Song, Xiaodan Song, Denny Zhou </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of ACL 2022</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2203.13240.pdf" style="color: #5c9e82; text-decoration: none">paper</a>] [<a href="./research/#exactline-acl22" style="color: #5c9e82; text-decoration: none">abstract</a>] [<a href="https://github.com/tensorflow/models/tree/master/official/projects/token_dropping" style="color: #5c9e82; text-decoration: none">code</a>] [<a href="https://drive.google.com/file/d/1-j54SpprZvnDGwLKCacF4xs2o0hYpTlL/view?usp=sharing" style="color: #5c9e82; text-decoration: none">talk</a>] [<a href="../misc-files/links/token-dropping-articles.html" style="color: #5c9e82; text-decoration: none">press</a>] [<a href="../misc-files/bibs/hou2022token.txt" style="color: #5c9e82; text-decoration: none">bibtex</a>]
</span>


<br>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2106.02278" style="font-size: 12pt; color: #245ED2; text-decoration: none"> AgreeSum: Agreement-Oriented Multi-Document Summarization </a> <br> </span>
<span style="line-height:170%"> Richard Yuanzhe Pang<sup>*</sup>, Adam D. Lelkes<sup>*</sup>, Vinh Q. Tran<sup>*</sup>, Cong Yu </span>
<br>
<span style="line-height:170%"> In <i>Findings of ACL 2021</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2106.02278.pdf" style="color: #245ED2; text-decoration: none">paper</a>] [<a href="./research/#exactline-acl21-b" style="color: #245ED2; text-decoration: none">abstract</a>] [<a href="https://github.com/google-research-datasets/AgreeSum" style="color: #245ED2; text-decoration: none">data</a>] [<a href="https://drive.google.com/file/d/1EYE3WLxqFpBHeSPU7zQ4gPZsxOE4wj5G/view?usp=sharing" style="color: #245ED2; text-decoration: none">short talk</a>] [<a href="../misc-files/bibs/pang2021agreesum.txt" style="color: #245ED2; text-decoration: none">bibtex</a>] </span>


<br>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2106.00840" style="font-size: 12pt; color: #22789D; text-decoration: none"> Comparing Test Sets with Item Response Theory  </a> <br> </span>
<span style="line-height:160%"> Clara Vania<sup>*</sup>, Phu Mon Htut<sup>*</sup>, William Huang<sup>*</sup>, Dhara Mungra, Richard Yuanzhe Pang, Jason Phang, Haokun Liu, Kyunghyun Cho, Samuel R. Bowman </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of ACL 2021</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2106.00840.pdf" style="color: #22789D; text-decoration: none">paper</a>] [<a href="./research/#exactline-acl21-a" style="color: #22789D; text-decoration: none">abstract</a>] [<a href="https://github.com/nyu-mll/nlu-test-sets" style="color: #22789D; text-decoration: none">code</a>] [<a href="../misc-files/bibs/vania2021comparing.txt" style="color: #22789D; text-decoration: none">bibtex</a>] </span>


<br>


<!-- <font size="3"> -->
<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2009.07839" style="font-size: 12pt; color: #245ED2; text-decoration: none"> Text Generation by Learning from Demonstrations </a> <br> </span>
<span style="line-height:170%"> Richard Yuanzhe Pang, He He </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of ICLR 2021</i> </span>
<br>
<span style="line-height:195%; font-size: 9pt"> tl;dr: a high-precision-generation training objective to address the train/test objective mismatch and history mismatch </span>
<br>
<span style="line-height:170%"> [<a href="../misc-files/pang+he-gold-paper.pdf" style="color: #245ED2; text-decoration: none">paper</a>] [<a href="./research/#exactline-iclr21" style="color: #245ED2; text-decoration: none">abstract</a>] [<a href="https://openreview.net/forum?id=RovX-uQ1Hua" style="color: #245ED2; text-decoration: none">openreview</a>] [<a href="../misc-files/pang+he-gold-poster.pdf" style="color: #245ED2; text-decoration: none">poster</a>] [<a href="../misc-files/pang+he-gold-slides.pdf" style="color: #245ED2; text-decoration: none">slides</a>] [<a href="
https://github.com/yzpang/gold-off-policy-text-gen-iclr21" style="color: #245ED2; text-decoration: none">code</a>] [<a href="../misc-files/pang-gold-discussion-2022-06.pdf" style="color: #245ED2; text-decoration: none">discussion</a>] [<a href="../misc-files/bibs/pang2021text.txt" style="color: #245ED2; text-decoration: none">bibtex</a>] | by others: [<a href="https://iclr-blog-track.github.io/2022/03/25/text-gen-via-lfd/" style="color: #245ED2; text-decoration: none">ICLR blog by other authors</a>] [<a href="https://www.science.org/stoken/author-tokens/ST-905/full" style="color: #245ED2; text-decoration: none">GOLD in AlphaCode, <i>Science</i></a>] </span>


<br>


<p class="small">
<span style="line-height:170%"> <u> Publications (2019-2020)</u> — main focus: text generation (textual style transfer, non-autoregressive translation, decoding), energy-based network in NLP </span> 


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/1911.02891" style="font-size: 12pt; color: #0A897D; text-decoration: none"> Improving Joint Training of Inference Networks and Structured Prediction Energy Networks </a> <br> </span>
<span style="line-height:170%"> Lifu Tu, Richard Yuanzhe Pang, Kevin Gimpel</span>
<br>
<span style="line-height:170%"> In <i>Proceedings of EMNLP 2020 Workshop on Structured Prediction for NLP (SPNLP)</i>; spotlight paper </span>
<br>
<span style="line-height:195%; font-size: 9pt"> tl;dr: improving fast approximate+amortized inference for energy-based models in NLP structured prediction </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/1911.02891.pdf" style="color: #0A897D; text-decoration: none">paper</a>] [<a href="./research/#exactline-spnlp20" style="color: #0A897D; text-decoration: none">abstract</a>] [<a href="../misc-files/pang-spen-infnet-joint-training-slides.pdf" style="color: #0A897D; text-decoration: none">my slides</a>] [<a href="../misc-files/bibs/tu2019improving.txt" style="color: #0A897D; text-decoration: none">bibtex</a>] </span>


<br>


<!-- <font size="3"> -->
<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2002.02492" style="font-size: 12pt; color: #0A897D; text-decoration: none"> Consistency of a Recurrent Language Model With Respect to Incomplete Decoding </a> <br> </span>
<span style="line-height:170%"> Sean Welleck<sup>*</sup>, Ilia Kulikov<sup>*</sup>, Jaedeok Kim, Richard Yuanzhe Pang, Kyunghyun Cho </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of EMNLP 2020</i> </span>
<br>  
<span style="line-height:170%"> Also appearing in the non-archival <i>DeepMath 2020</i> </span>
<br>  
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2002.02492.pdf" style="color: #0A897D; text-decoration: none">paper</a>] [<a href="./research/#exactline-emnlp20-a" style="color: #0A897D; text-decoration: none">abstract</a>] [<a href="https://github.com/uralik/consistency-lm" style="color: #0A897D; text-decoration: none">code</a>] [<a href="../misc-files/bibs/welleck2020consistency.txt" style="color: #0A897D; text-decoration: none">bibtex</a>] </span>


<br>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2005.00850" style="font-size: 12pt; color: #753DA4; text-decoration: none"> ENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine Translation </a> <br> </span>
<span style="line-height:170%"> Lifu Tu, Richard Yuanzhe Pang, Sam Wiseman, Kevin Gimpel</span>
<br>
<span style="line-height:170%"> In <i>Proceedings of ACL 2020</i> </span>
<br>
<span style="line-height:195%; font-size: 9pt"> tl;dr: a "soft" form of knowledge distillation for non-autoregressive MT </span>
<br>  
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2005.00850.pdf" style="color: #753DA4; text-decoration: none">paper</a>] [<a href="./research/#exactline-acl20-a" style="color: #753DA4; text-decoration: none">abstract</a>] [<a href="https://github.com/lifu-tu/ENGINE" style="color: #753DA4; text-decoration: none">code</a>] [<a href="../misc-files/bibs/tu2020engine.txt" style="color: #753DA4; text-decoration: none">bibtex</a>] </span>


<br>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2005.00628" style="font-size: 12pt; color: #22789D; text-decoration: none"> Intermediate-Task Transfer Learning with Pretrained Language Models: When and Why Does It Work? </a> <br> </span>
<span style="line-height:170%"> Yada Pruksachatkun<sup>*</sup>, Jason Phang<sup>*</sup>, Haokun Liu<sup>*</sup>, Phu Mon Htut<sup>*</sup>, Xiaoyi Zhang, Richard Yuanzhe Pang, Clara Vania, Katharina Kann, Samuel R. Bowman</span>
<br>
<span style="line-height:170%"> In <i>Proceedings of ACL 2020</i> </span>
<br>  
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2005.00628.pdf" style="color: #22789D; text-decoration: none">paper</a>] [<a href="./research/#exactline-acl20-b" style="color: #22789D; text-decoration: none">abstract</a>] [<a href="../misc-files/bibs/pruksachatkun2020intermediate.txt" style="color: #22789D; text-decoration: none">bibtex</a>] </span>


<br>


<!-- <font size="3"> -->
<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/1810.11878" style="font-size: 12pt; color: #245ED2; text-decoration: none"> Unsupervised Evaluation Metrics and Learning Criteria for Non-Parallel Textual Transfer </a> <br> </span>
<span style="line-height:170%"> Richard Yuanzhe Pang, Kevin Gimpel </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of EMNLP 2019 Workshop on Neural Generation and Translation (WNGT) </i> </span>
<br>
<span style="line-height:195%; font-size: 9pt"> tl;dr: proposing more dimensions for textual transfer evaluation metrics, and losses that target them </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/1810.11878.pdf" style="color: #245ED2; text-decoration: none">paper</a>] [<a href="https://arxiv.org/pdf/1810.11878.pdf#page=11" style="color: #245ED2; text-decoration: none">supplementals</a>] [<a href="./research/#exactline-wngt19-a" style="color: #245ED2; text-decoration: none">abstract</a>] [<a href="../misc-files/pang+gimpel-textual-transfer-poster.pdf" style="color: #245ED2; text-decoration: none">poster</a>] [<a href="../misc-files/bibs/pang2018unsupervised.txt" style="color: #245ED2; text-decoration: none">bibtex</a>] </span>


<br>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/1910.03747" style="font-size: 12pt; color: #245ED2; text-decoration: none"> The Daunting Task of Real-World Textual Style Transfer Auto-Evaluation </a> <br> </span>
<span style="line-height:170%"> Richard Yuanzhe Pang</span>
<br>
<span style="line-height:170%"> Extended abstract in <i>EMNLP 2019 Workshop on Neural Generation and Translation (WNGT)</i>; abstract in <i>Proceedings of the Workshop on Noisy User-generated Text (W-NUT)</i> 
<br>
<span style="line-height:195%; font-size: 9pt"> tl;dr: an opinion piece arguing that the research on textual style transfer and its evaluation are going astray </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/1910.03747.pdf" style="color: #245ED2; text-decoration: none">paper</a>] [<a href="./research/#exactline-wngt19-b" style="color: #245ED2; text-decoration: none">abstract</a>] [<a href="../misc-files/pang-textual-transfer-problem-poster.pdf" style="color: #245ED2; text-decoration: none">poster</a>] [<a href="../misc-files/bibs/pang2019daunting.txt" style="color: #245ED2; text-decoration: none">bibtex</a>] </span>




<br><br>


<p class="small">

More info: [<a href="https://www.semanticscholar.org/author/Richard-Yuanzhe-Pang/46230016" style="color: #4C8BF5; text-decoration: none" target="_blank">semantic scholar</a>] [<a href="https://scholar.google.com/citations?hl=en&user=vg_IkckAAAAJ" style="color: #4C8BF5; text-decoration: none" target="_blank">google scholar</a>] [<a href="https://dblp.org/pid/250/9059.html" style="color: #4C8BF5; text-decoration: none" target="_blank">dblp</a>] [<a href="../misc-files/abbreviations.txt" style="color: #4C8BF5; text-decoration: none" target="_blank">abbreviations</a>]








<h3 style="font-weight: 500">Discussion</h3>
<hr>


<p class="small">
<span style="font-weight:500"> <a href="../misc-files/pang-gold-discussion-2022-06.pdf" style="font-size: 12pt; color: #245ED2; text-decoration: none"> Discussion of GOLD </a> </span> <span style="line-height:170%"> [<a href="../misc-files/pang-gold-discussion-2022-06.pdf" style="color: #245ED2; text-decoration: none">pdf</a>] <br> </span>
<span style="line-height:170%"> June 2022 </span>
<br>
<span style="line-height:195%; font-size: 9pt"> tl;dr: GOLD does not maximize the expected reward. It maximizes the expected reward of training examples only. </span>







<h3 style="font-weight: 500">More research activities</h3>
<hr>


<p class="small">
<!-- <font size="3"> -->

<span style="line-height:170%"> <u>As an area chair</u> </span>
<ul class="small" style="margin-left: 16px;">
<li> ACL 2023 (summarization) </li>
</ul>


<p class="small">

<span style="line-height:170%"> <u>As a reviewer / program committee member</u> </span>
<ul class="small" style="margin-left: 16px;">
<li> Top ML/NLP venues: AAAI (2023), ACL Rolling Review (10,11/2021; 01,02,12/2022; 02/2023), ACL (2021), EMNLP (2021, 2022), ICLR (2022, 2023), ICLR blog post track (2022), ICML (2022, 2023), NeurIPS (2021 — top 8% reviewer, 2022), Transactions on Machine Learning Research (TMLR; 2022, 2023) [<a href="../misc-files/abbreviations.txt" style="color: #757575; text-decoration: none" target="_blank">abbreviations</a>] </li>
<li> Workshops: Novel Ideas in Learning-to-Learn through Interaction (NILLI 2021 at EMNLP 2021, NILLI 2022 at EMNLP 2022), Efficient Benchmarking in NLP (NLP Power at ACL 2022), Interactive Learning for NLP (InterNLP at NeurIPS 2022)</li>
<li> Other events: Mid-Atlantic Student Colloquium on Speech, Language, and Learning (2022, 2023) </li>
</ul>








<h3 style="font-weight: 500">Teaching</h3>
<hr>

<p class="small">
<!-- <font size="3"> -->
<span style="line-height:200%"> <u>External</u> </span>
<ul class="small" style="margin-left: 16px;">
<li> May 2022, <i>Teaching Assistant / Lab Instructor</i> (virtual), African Masters of Machine Intelligence (course: Deep Learning for NLP by Prof. Kyunghyun Cho and Prof. Duygu Ataman) [<a href="https://aimsammi.org/" style="color: #4d4d4d">AMMI site</a>] <br> </li>
</ul>


<p class="small">
<!-- <font size="3"> -->
<span style="line-height:200%"> <u>At New York University</u> </span>
<ul class="small" style="margin-left: 16px;">
<li> Spring 2022, <i>Section Leader / Teaching Assistant</i> (in-person), DS-GA 1012 / LING-GA 1012: Natural Language Understanding and Computational Semantics (Bowman; graduate-level) [<a href="https://docs.google.com/document/d/e/2PACX-1vRydPvLp9tNw1-45pp6IIl-jppX-tUfu0TQDVXRAiGA3CjIuJzBTzJo7cerQV08K8FqfUOYHBCPAggx/pub" style="color: #4d4d4d">syllabus</a>] <br> </li>
<li> January 2022, <i>Co-instructor / Co-organizer</i> (virtual), NYU AI School 2022 [<a href="https://nyu-mll.github.io/nyu-ai-school-2022/" style="color: #4d4d4d">site</a>] <br> </li> 
<li> Fall 2020, <i>Section Leader</i> (in-person), DS-GA 1008: Deep Learning (Cho, LeCun; graduate-level) [<a href="https://kyunghyuncho.me/courses/" style="color: #4d4d4d">syllabus</a>] <br> </li> 
</ul>


<p class="small">
<span style="line-height:200%"> <u>At the University of Chicago</u> </span>
<ul class="small" style="margin-left: 16px;">
<li> Spring 2017, <i>Course Assistant</i>, MATH 15910: Intro to Proofs in Analysis<br> </li>
<li> Winter 2017, <i>Course Assistant</i>, MATH 15910: Intro to Proofs in Analysis [<a href="../misc-files/math-15910-winter-2017-sol.html" style="color: #4d4d4d">sol]</a><br> </li>
<li> Winter 2017, <i>Grader</i>, CMSC 15200: Intro to Computer Science II<br> </li>
<li> Autumn 2016, <i>Teaching Assistant</i>, MATH 15300: Calculus III<br> </li>
</ul>

<!-- </font> -->
<p>








<h3 style="font-weight: 500">Presentations</h3>
<hr>





<p class="small">
<span style="line-height:170%"> <u> Selected presentations </u> </span>


<ul class="small" style="margin-left: 16px;">


<li> Talk on <i>QuALITY: Question Answering with Long Input Texts, Yes!</i> and <i> SQuALITY: Building a Long-Document Summarization Dataset the Hard Way</i>; Meta AI reading group in New York; October 2022 </li> 

<li> Talk titled <i>QuALITY: Question Answering with Long Input Texts, Yes!</i>; NAACL 2022 in Seattle; July 2022 [<a href="https://www.youtube.com/watch?v=WAhSW5iP8iw" style="color: #22789D; text-decoration: none">live talk</a>] </li> 


<li> Talk on <i>QuALITY: Question Answering with Long Input Texts, Yes!</i> in NYU's undergraduate course LING-UA 52 / DS-UA 203 ML for Language Understanding; March 2022 </li> 

<li> Talk on RL in text generation and <i>Text Generation by Learning from Demonstrations</i> in NYU's graduate course DS/LING-GA 1012 Natural Language Understanding; March 2022 </li> 

<li> Talk on question answering data collection; Apple; December 2021 </li>

<li> Talk titled <i>Text Generation by Learning from Demonstrations</i>; Samsung workshop; June 2021 [based on <a href="../misc-files/pang+he-gold-slides.pdf" style="color: #245ED2; text-decoration: none">this slide deck</a>] </li>

<li> Talk on structured prediction (specifically, inference networks and structured prediction energy networks); Bank of New York Mellon; September 2020 [based on <a href="../misc-files/pang-spen-infnet-joint-training-slides.pdf" style="color: #0A897D; text-decoration: none">this slide deck</a>] </li>   

<li> Talk titled <i>Text Generation by Offline RL</i>; Google Research New York; July 2020 </li>

<li> Poster presentation on <i>Learning Criteria and Evaluation Metrics for Textual Transfer between Non-Parallel Corpora</i>; NAACL 2019 NeuralGen workshop in Minneapolis; June 2019 </li>

<li> Talk titled <i>Learning Approximate Inference Networks and Structured Prediction Energy Networks</i>; Midwest Speech and Language Days (MSLD) 2019 in Chicago; May 2019 </li>

<li> Poster presentation on <i>Learning Criteria and Evaluation Metrics for Textual Transfer between Non-Parallel Corpora</i>; UChicago STEM Research Symposium in Chicago; October 2018 </li>


</ul>



<p class="small">
<span style="line-height:170%"> <u> Other conference presentations with associated proceeding papers </u> </span>

<ul class="small" style="margin-left: 16px;">

Please email for full CV.

<!-- <li> 5-min talk and poster presentation on <i>Text Generation by Learning from Demonstrations</i>; ICLR 2021; May 2021 [<a href="../misc-files/pang+he-gold-poster.pdf" style="color: #245ED2; text-decoration: none">poster</a>]</li>

<li> Poster presentation and lightning talk on <i>The Daunting Task of Real-World Textual Style Transfer Auto-Evaluation</i>; EMNLP 2019 WNGT workshop (poster) and W-NUT workshop (lightning talk) in Hong Kong, China; November 2019 [<a href="../misc-files/pang-textual-transfer-problem-poster.pdf" style="color: #245ED2; text-decoration: none">poster</a>]</li>


<li> Poster presentation on <i>Unsupervised Evaluation Metrics and Learning Criteria for Non-Parallel Textual Transfer</i>; EMNLP 2019 WNGT workshop in Hong Kong, China; November 2019 [<a href="../misc-files/pang+gimpel-textual-transfer-poster.pdf" style="color: #245ED2; text-decoration: none">poster</a>]</li>
 -->

</ul>









<!-- 
<h3 style="font-weight: 500">Relevant Coursework</h3>
<hr>

<p class="xsmall">
<span style="line-height:300%"> <u> At the University of Chicago (2015-2019) </u> </span>
<br>
CMSC 27230 - Honors Theory of Algorithms<br>
CMSC 25025 / STAT 37601 - Machine Learning and Large-Scale Data Analysis (grad level, Lafferty)<br>
CMSC 35400 / STAT 37710 - Machine Learning (grad level, Kondor)<br>
TTIC 31020 - Statistical Machine Learning (grad level, Shakhnarovich)<br>
TTIC 31190 - Natural Language Processing (grad level, Gimpel)<br>
TTIC 41000 - Spectral Techniques (grad level, Stratos)<br>
MATH 20300-20500 - Accelerated Real Analysis I, II, III<br>
MATH 20250, 25400-25500 - Abstract Linear Algebra; Abstract Algebra I, II<br>
BIOS 10602-10603 - Multiscale Modeling of Biological Systems I, II (computational biology)
 -->






<!-- 
<p>
 -->

<!-- <h3 style="font-weight: 500">Miscellaneous</h3>
<hr>

<p class="small">
I <a href="/writings/" style="color: #008016">write</a>. 
</p> -->




<br><br>



<p class="noindent" style="font-size: 11.5pt; margin-left: 0px; text-decoration: none">
<!-- <font size="3"> -->

Last updated: May 2, 2023. Contact: My NYU office is at <a href="https://www.google.com/maps/place/60+5th+Ave,+New+York,+NY+10011/" style="color: #57068C; text-decoration: none" target="_blank">60 5th Ave</a>. Get in touch at yzpang at _ dot edu (where _ is nyu or uchicago)!

<!-- </font> -->
</p>










</body>






  </div>
</div>
    </div>

    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
          <li><a href="https://www.linkedin.com/in/yuanzhe-richard-pang/"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://twitter.com/yzpang97"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2023 Yuanzhe (Richard) Pang. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.2.0/js/all.js"></script>








  </body>
</html>