---
layout: archive
---

{{ content }}

<!-- <h3 class="archive__subtitle">{{ site.data.ui-text[site.locale].recent_posts | default: "Recent Posts" }}</h3> -->

<html>
<head>
<style>
p.xsmall {
    line-height: 1.55;
    font-size: 9pt;
    margin-left: 40px; 
}

p.small {
    line-height: 1.55;
    font-size: 10pt;
    margin-left: 40px; 
}

ul.small {
    line-height: 1.55;
    font-size: 10pt;
}

p.small2 {
    line-height: 2.00;
    font-size: 10.5pt;
    margin-left: 40px; 
}

p.medium {
    line-height: 1.55;
    font-size: 11.5pt;
    margin-left: 40px; 
}

ul.medium {
    line-height: 1.55;
    font-size: 11.5pt;
}

p.big {
    line-height: 1.55;
}

p.noindent {
    line-height: 1.55;
    font-size: 11.5pt;
}


</style>
</head>
<body>









<p class="noindent">

Hello. I am a research scientist on the Fundamental AI Research (FAIR) team at Meta; previously I was on the AGI Foundations / Reasoning team. I have been working on a range of topics in recent years: language model coding and reasoning (for Llama reasoning), RL, instruction following, post-training of Llama 3.3, post-training and alignment algorithms in general, etc. Currently and in the near future (Summer 2025 —), I am working full-time on building Meta's next LLM.

<br><br>

I completed my Ph.D. in computer science at the Courant Institute of Mathematical Sciences at New York University. I was mentored by <a href="https://hhexiy.github.io" style="color: #757575; text-decoration: none" target="_blank">He He</a>, <a href="http://www.kyunghyuncho.me" style="color: #757575; text-decoration: none" target="_blank">Kyunghyun Cho</a>, and <a href="https://scholar.google.com/citations?hl=en&user=lMkTx0EAAAAJ" style="color: #757575; text-decoration: none" target="_blank">Jason Weston</a>. My Ph.D. focused on natural language processing and machine learning: text generation (learning from reward, learning from feedback, machine translation, dialogue, decoding), reasoning, evaluation, multi-modal NLP, etc.; I also had moderate experience in pretraining. During grad school, I spent two summers (2020, 2021) at Google. I co-organized and co-instructed NYU AI School mainly targeting NYC-area undergrads (2022, 2023); I also co-instructed the Deep Learning for NLP course at the African Masters of Machine Intelligence (2022). Prior to grad school, I graduated from the University of Chicago (B.S. in mathematics, computer science). At UChicago and TTIC, I worked on text generation and structured prediction with Drs. <a href="http://ttic.uchicago.edu/~kgimpel/" style="color: #757575; text-decoration: none" target="_blank">Kevin Gimpel</a> and <a href="https://karlstratos.com/" style="color: #757575; text-decoration: none" target="_blank">Karl Stratos</a>. 

<br><br>

[<a href="https://scholar.google.com/citations?hl=en&user=vg_IkckAAAAJ" style="color: #4C8BF5; text-decoration: none" target="_blank">google scholar</a>] [<a href="https://dblp.org/pid/250/9059.html" style="color: #4C8BF5; text-decoration: none" target="_blank">dblp</a>] [<a href="https://www.linkedin.com/in/yuanzhe-richard-pang/" style="color: #4C8BF5; text-decoration: none" target="_blank">linkedin</a>] [<a href="./misc-files/links/untitled.html" style="color: #4C8BF5; text-decoration: none" target="_blank">mail</a>] [<a href="https://twitter.com/yzpang_" style="color: #4C8BF5; text-decoration: none" target="_blank">twitter</a>] [<a href="../misc-files/abbreviations.txt" style="color: #4C8BF5; text-decoration: none" target="_blank">abbreviations</a>]

</font>
<p>











<h3 style="font-weight: 500">Research</h3>





<p class="small">
<!-- </font> -->
<!-- <span style="line-height:170%"> 
<i>Primary</i> research subfields: <a style="color: #245ED2; text-decoration: none">text generation</a> (including <a style="color: #753DA4; text-decoration: none">machine translation</a>) and <a style="color: #245ED2; text-decoration: none">learning from rewards</a>, <a style="color: #22789D; text-decoration: none">language understanding</a>, <a style="color: #1E8552; text-decoration: none">reasoning</a>, and <a style="color: #757575; text-decoration: none">others</a>. 
</span>
 -->

<!-- <br> -->

<hr>


<!-- <p class="small">
<span style="line-height:170%"> <u> Preprints </u> </span>







<br><br>
 -->



<!-- 
<p class="small">
<span style="line-height:170%"> <u> Preprints </u> </span>

 -->




<p class="small">
<span style="line-height:170%"> <b><u> OVERVIEW OF SELECTED RESEARCH DIRECTIONS (outdated!) </u> </b></span>


<ul class="small" style="margin-left: 16px;">
<li> <b>Learning from rewards in text generation</b>: <a href="https://arxiv.org/abs/2009.07839" style="color: #245ED2; text-decoration: none">GOLD</a> (offline RL, used in AlphaCode 1&2), <a href="https://arxiv.org/abs/2112.08670" style="color: #245ED2; text-decoration: none">amortized noisy channel NMT</a> (off-policy RL & knowledge distillation), <a href="https://arxiv.org/abs/2211.08714" style="color: #245ED2; text-decoration: none">reward gaming</a> (on-policy RL), <a href="https://arxiv.org/abs/2106.02278" style="color: #245ED2; text-decoration: none">AgreeSum</a> (on-policy RL for multi-doc summarization), <a href="https://arxiv.org/abs/2005.00850" style="color: #245ED2; text-decoration: none">ENGINE for non-autoregressive NMT</a> ("soft" knowledge distillation), <a href="https://arxiv.org/abs/2307.14117" style="color: #245ED2; text-decoration: none">implicit feedback in dialogue</a> (extracting implicit reward from deployment data), <a href="https://arxiv.org/abs/2401.10020" style="color: #245ED2; text-decoration: none">self-rewarding LLM</a>, <a href="https://arxiv.org/abs/2404.19733" style="color: #245ED2; text-decoration: none">iterative reasoning preference optimization (IRPO)</a>, etc. </li>

<li> <b>Reasoning</b>: <a href="https://arxiv.org/abs/2305.15269" style="color: #1E8552; text-decoration: none">PrOntoQA-OOD</a> (deductive reasoning), <a href="https://arxiv.org/abs/2404.19733" style="color: #1E8552; text-decoration: none">IRPO</a> (also related to reasoning) </li>

<li> <b>Evaluation</b>: <a href="https://arxiv.org/abs/2112.08608" style="color: #22789D; text-decoration: none">QuALITY</a> (long-document QA; related: <a href="https://arxiv.org/abs/2205.11465" style="color: #22789D; text-decoration: none">SQuALITY</a> long-document summarization), <a href="https://arxiv.org/abs/2311.12022" style="color: #22789D; text-decoration: none"> GPQA</a> (graduate-level Google-proof QA) </li>


</ul>
</p>


<p class="small">
<span style="line-height:170%"> <u> Publications and preprints (2024-) </u> </span>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2510.01135" style="font-size: 11pt; color: #245ED2; text-decoration: none"> Prompt Curriculum Learning for Efficient LLM Post-Training </a> <br> </span>
<span style="line-height:170%"> Zhaolin Gao, Joongwon Kim, Wen Sun, Thorsten Joachims, Sid Wang, Richard Yuanzhe Pang, Liang Tan</span>
<br>
<span style="line-height:170%"> In <i>Proceedings of ICLR 2026</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2510.01135" style="color: #245ED2; text-decoration: none">paper</a>] [<a href="../misc-files/bibs/gao2025prompt.txt" style="color: #245ED2; text-decoration: none">bibtex</a>]
</span>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2511.10507" style="font-size: 11pt; color: #245ED2; text-decoration: none"> Rubric-Based Benchmarking and Reinforcement Learning for Advancing LLM Instruction Following </a> <br> </span>
<span style="line-height:170%; font-size: 8pt"> Yun He, Wenzhe Li, Hejia Zhang, Songlin Li, Karishma Mandyam, Sopan Khosla, Yuanhao Xiong, Nanshu Wang, Selina Peng, Beibin Li, Shengjie Bi, Shishir G. Patil, Qi Qi, Shengyu Feng, Julian Katz-Samuels, Richard Yuanzhe Pang, Sujan Gonugondla, Hunter Lang, Yue Yu, Yundi Qian, Maryam Fazel-Zarandi, Licheng Yu, Amine Benhalloum, Hany Awadalla, Manaal Faruqui</span>
<br>
<span style="line-height:170%"> <i>Preprint</i>, November 2025 </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2511.10507" style="color: #245ED2; text-decoration: none">paper</a>] [<a href="https://huggingface.co/datasets/meta-llama/AdvancedIF" style="color: #245ED2; text-decoration: none">data</a>] [<a href="https://github.com/facebookresearch/AdvancedIF" style="color: #245ED2; text-decoration: none">code</a>] [<a href="../misc-files/bibs/he2025rubric.txt" style="color: #245ED2; text-decoration: none">bibtex</a>] | by others: [<a href="../misc-files/links/advancedif-others.html" style="color: #245ED2; text-decoration: none">blogs</a>]
</span>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2411.04109" style="font-size: 11pt; color: #1E8552; text-decoration: none"> Self-Consistency Preference Optimization </a> <br> </span>
<span style="line-height:170%"> Archiki Prasad, Weizhe Yuan, Richard Yuanzhe Pang, Jing Xu, Maryam Fazel-Zarandi, Mohit Bansal, Sainbayar Sukhbaatar, Jason Weston, Jane Yu</span>
<br>
<span style="line-height:170%"> In <i>Proceedings of ICML 2025</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2411.04109.pdf" style="color: #1E8552; text-decoration: none">paper</a>] [<a href="../misc-files/bibs/prasad2024self.txt" style="color: #1E8552; text-decoration: none">bibtex</a>] 
</span>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2412.04703" style="font-size: 11pt; color: #1E8552; text-decoration: none"> Transformers Struggle to Learn to Search </a> <br> </span>
<span style="line-height:170%"> Abulhair Saparov, Srushti Pawar, Shreyas Pimpalgaonkar, Nitish Joshi, Richard Yuanzhe Pang, Vishakh Padmakumar, Seyed Mehran Kazemi, Najoung Kim, He He </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of ICLR 2025</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2412.04703.pdf" style="color: #1E8552; text-decoration: none">paper</a>] [<a href="https://openreview.net/forum?id=9cQB1Hwrtw" style="color: #1E8552; text-decoration: none">openreview</a>] [<a href="../misc-files/bibs/saparov2024transformers.txt" style="color: #1E8552; text-decoration: none">bibtex</a>] 
</span>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2411.16646" style="font-size: 11pt; color: #245ED2; text-decoration: none"> Self-Generated Critiques Boost Reward Modeling for Language Models </a> <br> </span>
<span style="line-height:170%"> Yue Yu, Zhengxing Chen, Aston Zhang, Liang Tan, Chenguang Zhu, Richard Yuanzhe Pang, Yundi Qian, Xuewei Wang, Suchin Gururangan, Chao Zhang, Melanie Kambadur, Dhruv Mahajan, Rui Hou </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of NAACL 2025</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2411.16646.pdf" style="color: #245ED2; text-decoration: none">paper</a>] [<a href="../misc-files/bibs/yu2024self.txt" style="color: #245ED2; text-decoration: none">bibtex</a>] 
</span>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2404.19733" style="font-size: 11pt; color: #1E8552; text-decoration: none"> Iterative Reasoning Preference Optimization </a> <br> </span>
<span style="line-height:170%"> Richard Yuanzhe Pang, Weizhe Yuan, Kyunghyun Cho, He He, Sainbayar Sukhbaatar, Jason Weston</span>
<br>
<span style="line-height:170%"> In <i>Proceedings of NeurIPS 2024</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2404.19733.pdf" style="color: #1E8552; text-decoration: none">paper</a>] [<a href="./research/#exactline-iterative-rpo" style="color: #1E8552; text-decoration: none">abstract</a>] [<a href="../misc-files/bibs/pang2024iterative.txt" style="color: #1E8552; text-decoration: none">bibtex</a>] | by others: [<a href="../misc-files/links/irpo-others.html" style="color: #1E8552; text-decoration: none">notable use cases (ESM3, Llama 3)</a>]
</span>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2408.02666" style="font-size: 11pt; color: #245ED2; text-decoration: none"> Self-Taught Evaluators </a> <br> </span>
<span style="line-height:170%"> Tianlu Wang, Ilia Kulikov, Olga Golovneva, Ping Yu, Weizhe Yuan, Jane Dwivedi-Yu, Richard Yuanzhe Pang, Maryam Fazel-Zarandi, Jason Weston, Xian Li</span>
<br>
<span style="line-height:170%"> <i>Preprint</i>, August 2024 </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2408.02666.pdf" style="color: #245ED2; text-decoration: none">paper</a>] [<a href="./research/#exactline-self-taught-evaluators" style="color: #245ED2; text-decoration: none">abstract</a>] [<a href="https://github.com/facebookresearch/RAM/tree/main/projects/self_taught_evaluator" style="color: #245ED2; text-decoration: none">code</a>] [<a href="https://huggingface.co/facebook/Self-taught-evaluator-llama3.1-70B" style="color: #245ED2; text-decoration: none">model</a>] [<a href="https://huggingface.co/datasets/facebook/Self-taught-evaluator-DPO-data" style="color: #245ED2; text-decoration: none">synthetic data</a>] [<a href="../misc-files/bibs/wang2024self.txt" style="color: #245ED2; text-decoration: none">bibtex</a>] | by others: [<a href="../misc-files/links/self-taught-evaluators-articles.html" style="color: #245ED2; text-decoration: none">press</a>]
</span>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2401.10020" style="font-size: 11pt; color: #245ED2; text-decoration: none"> Self-Rewarding Language Models </a> <br> </span>
<span style="line-height:170%"> Weizhe Yuan, Richard Yuanzhe Pang, Kyunghyun Cho, Xian Li, Sainbayar Sukhbaatar, Jing Xu, Jason Weston</span>
<br>
<span style="line-height:170%"> In <i>Proceedings of ICML 2024</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2401.10020.pdf" style="color: #245ED2; text-decoration: none">paper</a>] [<a href="./research/#exactline-self-rewarding-lm" style="color: #245ED2; text-decoration: none">abstract</a>] [<a href="../misc-files/bibs/yuan2024self.txt" style="color: #245ED2; text-decoration: none">bibtex</a>] | by others: [<a href="../misc-files/links/self-reward-articles.html" style="color: #245ED2; text-decoration: none">press and other mentions</a>]
</span>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2311.12022" style="font-size: 11pt; color: #22789D; text-decoration: none"> GPQA: A Graduate-Level Google-Proof Q&A Benchmark </a> <br> </span>
<span style="line-height:170%"> David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, Samuel R. Bowman </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of Conference on Language Modeling (COLM) 2024</i>; spotlight (2% of submissions) </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2311.12022.pdf" style="color: #22789D; text-decoration: none">paper</a>] [<a href="./research/#exactline-gpqa" style="color: #22789D; text-decoration: none">abstract</a>] [<a href="https://github.com/idavidrein/gpqa" style="color: #22789D; text-decoration: none">data & code</a>] [<a href="https://openreview.net/forum?id=Ti67584b98#discussion" style="color: #22789D; text-decoration: none">openreview</a>] [<a href="../misc-files/bibs/rein2023gpqa.txt" style="color: #22789D; text-decoration: none">bibtex</a>] | by others: [<a href="../misc-files/links/gpqa-articles.html" style="color: #22789D; text-decoration: none">press, mentions, and notable use cases</a>] 
</span>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2405.17247" style="font-size: 11pt; color: #757575; text-decoration: none"> An Introduction to Vision-Language Modeling </a> <br> </span>
<span style="line-height:170%; font-size: 8pt"> Florian Bordes, Richard Yuanzhe Pang, Anurag Ajay, Alexander C. Li, Adrien Bardes, Suzanne Petryk, Oscar Mañas, Zhiqiu Lin, Anas Mahmoud, Bargav Jayaraman, Mark Ibrahim, Melissa Hall, Yunyang Xiong, Jonathan Lebensold, Candace Ross, Srihari Jayakumar, Chuan Guo, Diane Bouchacourt, Haider Al-Tahan, Karthik Padthe, Vasu Sharma, Hu Xu, Xiaoqing Ellen Tan, Megan Richards, Samuel Lavoie, Pietro Astolfi, Reyhane Askari Hemmat, Jun Chen, Kushal Tirumala, Rim Assouel, Mazda Moayeri, Arjang Talattof, Kamalika Chaudhuri, Zechun Liu, Xilun Chen, Quentin Garrido, Karen Ullrich, Aishwarya Agrawal, Kate Saenko, Asli Celikyilmaz, Vikas Chandra </span>
<br>
<span style="line-height:170%"> <i>Preprint</i>, May 2024 </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2405.17247.pdf" style="color: #757575; text-decoration: none">paper</a>] [<a href="./research/#exactline-vlm" style="color: #757575; text-decoration: none">abstract</a>] [<a href="../misc-files/bibs/bordes2024introduction.txt" style="color: #757575; text-decoration: none">bibtex</a>] 
</span>



<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2307.14117" style="font-size: 11pt; color: #245ED2; text-decoration: none"> Leveraging Implicit Feedback from Deployment Data in Dialogue </a> <br> </span>
<span style="line-height:170%"> Richard Yuanzhe Pang, Stephen Roller, Kyunghyun Cho, He He, Jason Weston </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of EACL 2024</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2307.14117.pdf" style="color: #245ED2; text-decoration: none">paper</a>] [<a href="./research/#exactline-dialogue-implicit-feedback" style="color: #245ED2; text-decoration: none">abstract</a>] [<a href="../misc-files/bibs/pang2023leveraging.txt" style="color: #245ED2; text-decoration: none">bibtex</a>]
</span>


<br><br>


<p class="small">
<span style="line-height:170%"> <u> Publications (2021-2023)</u> — <b>main focus</b>: text generation (learning from rewards, RL), long-document understanding (question answering, summarization), reasoning </span>



<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2305.15269" style="font-size: 11pt; color: #1E8552; text-decoration: none"> Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples </a> <br> </span>
<span style="line-height:170%"> Abulhair Saparov, Richard Yuanzhe Pang, Vishakh Padmakumar, Nitish Joshi, Seyed Mehran Kazemi, Najoung Kim*, He He* </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of NeurIPS 2023</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2305.15269.pdf" style="color: #1E8552; text-decoration: none">paper</a>] [<a href="./research/#exactline-reasoning" style="color: #1E8552; text-decoration: none">abstract</a>] [<a href="../misc-files/pang-reasoning-poster-icml-klr-workshop-2023.pdf" style="color: #1E8552; text-decoration: none">poster at <i>ICML 2023 Knowledge and Logical Reasoning Workshop</i></a>] [<a href="../misc-files/bibs/saparov2023testing.txt" style="color: #1E8552; text-decoration: none">bibtex</a>]
</span>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2303.04562" style="font-size: 11pt; color: #245ED2; text-decoration: none"> Extrapolative Controlled Sequence Generation via Iterative Refinement </a> <br> </span>
<span style="line-height:170%"> Vishakh Padmakumar, Richard Yuanzhe Pang, He He, Ankur P. Parikh </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of ICML 2023</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2303.04562.pdf" style="color: #245ED2; text-decoration: none">paper</a>] [<a href="./research/#exactline-icml23" style="color: #245ED2; text-decoration: none">abstract</a>] [<a href="../misc-files/bibs/padmakumar2023extrapolative.txt" style="color: #245ED2; text-decoration: none">bibtex</a>]
</span>


<br>
<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2211.08714" style="font-size: 11pt; color: #245ED2; text-decoration: none"> Reward Gaming in Conditional Text Generation </a> <br> </span>
<span style="line-height:170%"> Richard Yuanzhe Pang, Vishakh Padmakumar, Thibault Sellam, Ankur P. Parikh, He He </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of ACL 2023</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2211.08714.pdf" style="color: #245ED2; text-decoration: none">paper</a>] [<a href="./research/#exactline-acl23-b" style="color: #245ED2; text-decoration: none">abstract</a>] [<a href="https://youtu.be/CdX5do_3geE" style="color: #245ED2; text-decoration: none">15-min talk</a>] [<a href="../misc-files/pang-reward-gaming-slides-acl2023.pdf" style="color: #245ED2; text-decoration: none">slides</a>] [<a href="../misc-files/bibs/pang2023reward.txt" style="color: #245ED2; text-decoration: none">bibtex</a>]
</span>


<br>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2208.12852" style="font-size: 11pt; color: #757575; text-decoration: none"> What Do NLP Researchers Believe? Results of the NLP Community Metasurvey </a> <br> </span>
<span style="line-height:170%"> Julian Michael, Ari Holtzman, Alicia Parrish, Aaron Mueller, Alex
 Wang, Angelica Chen, Divyam Madaan, Nikita Nangia, Richard Yuanzhe Pang, Jason Phang, Samuel R. Bowman </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of ACL 2023</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2208.12852.pdf" style="color: #757575; text-decoration: none">paper</a>] [<a href="./research/#exactline-acl23-a" style="color: #757575; text-decoration: none">abstract</a>] [<a href="https://nlpsurvey.net/" style="color: #757575; text-decoration: none">website</a>] [<a href="../misc-files/bibs/michael2023nlp.txt" style="color: #757575; text-decoration: none">bibtex</a>] | by others: [<a href="../misc-files/links/survey-articles.html" style="color: #757575; text-decoration: none">press</a>]
</span>


<br>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2205.11465" style="font-size: 11pt; color: #22789D; text-decoration: none"> SQuALITY: Building a Long-Document Summarization Dataset the Hard Way </a> <br> </span>
<span style="line-height:170%"> Alex Wang, Richard Yuanzhe Pang, Angelica Chen, Jason Phang, Samuel R. Bowman </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of EMNLP 2022</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2205.11465.pdf" style="color: #22789D; text-decoration: none">paper</a>] [<a href="./research/#exactline-emnlp22" style="color: #22789D; text-decoration: none">abstract</a>] [<a href="https://github.com/nyu-mll/SQuALITY/tree/main/data" style="color: #22789D; text-decoration: none">data</a>] [<a href="https://github.com/nyu-mll/SQuALITY" style="color: #22789D; text-decoration: none">code</a>] [<a href="../misc-files/bibs/wang2022squality.txt" style="color: #22789D; text-decoration: none">bibtex</a>] | by others: [<a href="https://www.zero.scrolls-benchmark.com" style="color: #22789D; text-decoration: none">zeroscrolls</a>]
</span>


<br>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2112.08670" style="font-size: 11pt; color: #753DA4; text-decoration: none"> Amortized Noisy Channel Neural Machine Translation </a> <br> </span>
<span style="line-height:170%"> Richard Yuanzhe Pang, He He, Kyunghyun Cho </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of INLG 2022</i>; best presentation award</span>
<br>
<span style="line-height:195%; font-size: 9pt"> tl;dr: amortizing the inference cost of "beam search and rerank" – learning to rerank without explicitly reranking </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2112.08670.pdf" style="color: #753DA4; text-decoration: none">paper</a>] [<a href="./research/#exactline-amortized-noisy-channel" style="color: #753DA4; text-decoration: none">abstract</a>] [<a href="https://www.youtube.com/watch?v=EqpNw7JJvI4" style="color: #753DA4; text-decoration: none">talk</a>] [<a href="../misc-files/pang-amortized-poster-inlg2022.pdf" style="color: #753DA4; text-decoration: none">poster</a>] [<a href="../misc-files/bibs/pang2022amortized.txt" style="color: #753DA4; text-decoration: none">bibtex</a>]</span>



<br>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2112.08608" style="font-size: 11pt; color: #22789D; text-decoration: none"> QuALITY: Question Answering with Long Input Texts, Yes! </a> <br> </span>
<span style="line-height:160%"> Richard Yuanzhe Pang<sup>*</sup>, Alicia Parrish<sup>*</sup>, Nitish Joshi<sup>*</sup>, Nikita Nangia, Jason Phang, Angelica Chen, Vishakh Padmakumar, Johnny Ma, Jana Thompson, He He, Samuel R. Bowman </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of NAACL 2022</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2112.08608.pdf" style="color: #22789D; text-decoration: none">paper</a>] [<a href="./research/#exactline-quality" style="color: #22789D; text-decoration: none">abstract</a>] [<a href="https://github.com/nyu-mll/quality/tree/main/data" style="color: #22789D; text-decoration: none">data</a>] [<a href="https://github.com/nyu-mll/quality/tree/main/baselines" style="color: #22789D; text-decoration: none">code</a>] [<a href="https://nyu-mll.github.io/quality/" style="color: #22789D; text-decoration: none">leaderboard</a>] [<a href="https://www.youtube.com/watch?v=WAhSW5iP8iw" style="color: #22789D; text-decoration: none">15-min live talk</a>] [<a href="../misc-files/pang-quality-slides-naacl2022.pdf" style="color: #22789D; text-decoration: none">slides</a>] [<a href="../misc-files/bibs/pang2022quality.txt" style="color: #22789D; text-decoration: none">bibtex</a>] | by others: [<a href="https://www.tensorflow.org/datasets/catalog/quality" style="color: #22789D; text-decoration: none">tfds</a>] [<a href="https://www.metaculus.com/questions/9628/question-answering-on-long-texts-by-2025/" style="color: #22789D; text-decoration: none">forecast</a>] [<a href="https://www.science.org/content/article/computers-ace-iq-tests-still-make-dumb-mistakes-can-different-tests-help" style="color: #22789D; text-decoration: none">press mention by <i>Science</i></a>] [<a href="https://www.scrolls-benchmark.com/" style="color: #22789D; text-decoration: none">scrolls</a>] [<a href="https://www.zero.scrolls-benchmark.com" style="color: #22789D; text-decoration: none">zeroscrolls</a>] </span>


<br>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2203.13240" style="font-size: 11pt; color: #757575; text-decoration: none"> Token Dropping for Efficient BERT Pretraining </a> <br> </span>
<span style="line-height:170%"> Le Hou<sup>*</sup>, Richard Yuanzhe Pang<sup>*</sup>, Tianyi Zhou, Yuexin Wu, Xinying Song, Xiaodan Song, Denny Zhou </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of ACL 2022</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2203.13240.pdf" style="color: #757575; text-decoration: none">paper</a>] [<a href="./research/#exactline-acl22" style="color: #757575; text-decoration: none">abstract</a>] [<a href="https://github.com/tensorflow/models/tree/master/official/projects/token_dropping" style="color: #757575; text-decoration: none">code</a>] [<a href="https://drive.google.com/file/d/1-j54SpprZvnDGwLKCacF4xs2o0hYpTlL/view?usp=sharing" style="color: #757575; text-decoration: none">talk</a>]  [<a href="../misc-files/bibs/hou2022token.txt" style="color: #757575; text-decoration: none">bibtex</a>] | by others: [<a href="../misc-files/links/token-dropping-articles.html" style="color: #757575; text-decoration: none">press</a>] [<a href="https://arxiv.org/abs/2305.15273" style="color: #757575; text-decoration: none">improvement</a>]
</span>


<br>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2106.02278" style="font-size: 11pt; color: #245ED2; text-decoration: none"> AgreeSum: Agreement-Oriented Multi-Document Summarization </a> <br> </span>
<span style="line-height:170%"> Richard Yuanzhe Pang<sup>*</sup>, Adam D. Lelkes<sup>*</sup>, Vinh Q. Tran<sup>*</sup>, Cong Yu </span>
<br>
<span style="line-height:170%"> In <i>Findings of ACL 2021</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2106.02278.pdf" style="color: #245ED2; text-decoration: none">paper</a>] [<a href="./research/#exactline-acl21-b" style="color: #245ED2; text-decoration: none">abstract</a>] [<a href="https://github.com/google-research-datasets/AgreeSum" style="color: #245ED2; text-decoration: none">data</a>] [<a href="https://drive.google.com/file/d/1EYE3WLxqFpBHeSPU7zQ4gPZsxOE4wj5G/view?usp=sharing" style="color: #245ED2; text-decoration: none">short talk</a>] [<a href="../misc-files/bibs/pang2021agreesum.txt" style="color: #245ED2; text-decoration: none">bibtex</a>] </span>


<br>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2106.00840" style="font-size: 11pt; color: #757575; text-decoration: none"> Comparing Test Sets with Item Response Theory  </a> <br> </span>
<span style="line-height:160%"> Clara Vania<sup>*</sup>, Phu Mon Htut<sup>*</sup>, William Huang<sup>*</sup>, Dhara Mungra, Richard Yuanzhe Pang, Jason Phang, Haokun Liu, Kyunghyun Cho, Samuel R. Bowman </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of ACL 2021</i> </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2106.00840.pdf" style="color: #757575; text-decoration: none">paper</a>] [<a href="./research/#exactline-acl21-a" style="color: #757575; text-decoration: none">abstract</a>] [<a href="https://github.com/nyu-mll/nlu-test-sets" style="color: #757575; text-decoration: none">code</a>] [<a href="../misc-files/bibs/vania2021comparing.txt" style="color: #757575; text-decoration: none">bibtex</a>] </span>


<br>


<!-- <font size="3"> -->
<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2009.07839" style="font-size: 11pt; color: #245ED2; text-decoration: none"> Text Generation by Learning from Demonstrations </a> <br> </span>
<span style="line-height:170%"> Richard Yuanzhe Pang, He He </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of ICLR 2021</i> </span>
<br>
<span style="line-height:195%; font-size: 9pt"> tl;dr: a high-precision-generation training objective to address the train/test objective mismatch and history mismatch </span>
<br>
<span style="line-height:170%"> [<a href="../misc-files/pang+he-gold-paper.pdf" style="color: #245ED2; text-decoration: none">paper</a>] [<a href="./research/#exactline-iclr21" style="color: #245ED2; text-decoration: none">abstract</a>] [<a href="https://openreview.net/forum?id=RovX-uQ1Hua" style="color: #245ED2; text-decoration: none">openreview</a>] [<a href="../misc-files/pang+he-gold-poster.pdf" style="color: #245ED2; text-decoration: none">poster</a>] [<a href="../misc-files/pang+he-gold-slides.pdf" style="color: #245ED2; text-decoration: none">slides</a>] [<a href="
https://github.com/yzpang/gold-off-policy-text-gen-iclr21" style="color: #245ED2; text-decoration: none">code</a>] [<a href="../misc-files/pang-gold-discussion-2022-06.pdf" style="color: #245ED2; text-decoration: none">discussion</a>] [<a href="../misc-files/bibs/pang2021text.txt" style="color: #245ED2; text-decoration: none">bibtex</a>] | by others: [<a href="https://iclr-blog-track.github.io/2022/03/25/text-gen-via-lfd/" style="color: #245ED2; text-decoration: none">ICLR blog by other authors</a>] [<a href="https://www.science.org/stoken/author-tokens/ST-905/full" style="color: #245ED2; text-decoration: none">GOLD in AlphaCode, <i>Science</i></a>] [<a href="https://storage.googleapis.com/deepmind-media/AlphaCode2/AlphaCode2_Tech_Report.pdf" style="color: #245ED2; text-decoration: none">GOLD as the main learning objective in AlphaCode 2, Dec 2023</a>] </span>


<br><br>


<p class="small">
<span style="line-height:170%"> <u> Publications (2019-2020)</u> — <b>main focus</b>: text generation (textual style transfer, non-autoregressive translation, decoding), energy-based network in NLP </span> 


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/1911.02891" style="font-size: 11pt; color: #245ED2; text-decoration: none"> Improving Joint Training of Inference Networks and Structured Prediction Energy Networks </a> <br> </span>
<span style="line-height:170%"> Lifu Tu, Richard Yuanzhe Pang, Kevin Gimpel</span>
<br>
<span style="line-height:170%"> In <i>Proceedings of EMNLP 2020 Workshop on Structured Prediction for NLP (SPNLP)</i>; spotlight paper </span>
<br>
<span style="line-height:195%; font-size: 9pt"> tl;dr: improving fast approximate+amortized inference for energy-based models in NLP structured prediction </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/1911.02891.pdf" style="color: #245ED2; text-decoration: none">paper</a>] [<a href="./research/#exactline-spnlp20" style="color: #245ED2; text-decoration: none">abstract</a>] [<a href="../misc-files/pang-spen-infnet-joint-training-slides.pdf" style="color: #245ED2; text-decoration: none">my slides</a>] [<a href="../misc-files/bibs/tu2019improving.txt" style="color: #245ED2; text-decoration: none">bibtex</a>] </span>


<br>


<!-- <font size="3"> -->
<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2002.02492" style="font-size: 11pt; color: #245ED2; text-decoration: none"> Consistency of a Recurrent Language Model With Respect to Incomplete Decoding </a> <br> </span>
<span style="line-height:170%"> Sean Welleck<sup>*</sup>, Ilia Kulikov<sup>*</sup>, Jaedeok Kim, Richard Yuanzhe Pang, Kyunghyun Cho </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of EMNLP 2020</i> </span>
<br>  
<span style="line-height:170%"> Also appearing in the non-archival <i>DeepMath 2020</i> </span>
<br>  
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2002.02492.pdf" style="color: #245ED2; text-decoration: none">paper</a>] [<a href="./research/#exactline-emnlp20-a" style="color: #245ED2; text-decoration: none">abstract</a>] [<a href="https://github.com/uralik/consistency-lm" style="color: #245ED2; text-decoration: none">code</a>] [<a href="../misc-files/bibs/welleck2020consistency.txt" style="color: #245ED2; text-decoration: none">bibtex</a>] </span>


<br>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2005.00850" style="font-size: 11pt; color: #753DA4; text-decoration: none"> ENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine Translation </a> <br> </span>
<span style="line-height:170%"> Lifu Tu, Richard Yuanzhe Pang, Sam Wiseman, Kevin Gimpel</span>
<br>
<span style="line-height:170%"> In <i>Proceedings of ACL 2020</i> </span>
<br>
<span style="line-height:195%; font-size: 9pt"> tl;dr: a "soft" form of knowledge distillation for non-autoregressive MT </span>
<br>  
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2005.00850.pdf" style="color: #753DA4; text-decoration: none">paper</a>] [<a href="./research/#exactline-acl20-a" style="color: #753DA4; text-decoration: none">abstract</a>] [<a href="https://github.com/lifu-tu/ENGINE" style="color: #753DA4; text-decoration: none">code</a>] [<a href="../misc-files/bibs/tu2020engine.txt" style="color: #753DA4; text-decoration: none">bibtex</a>] </span>


<br>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/2005.00628" style="font-size: 11pt; color: #757575; text-decoration: none"> Intermediate-Task Transfer Learning with Pretrained Language Models: When and Why Does It Work? </a> <br> </span>
<span style="line-height:170%"> Yada Pruksachatkun<sup>*</sup>, Jason Phang<sup>*</sup>, Haokun Liu<sup>*</sup>, Phu Mon Htut<sup>*</sup>, Xiaoyi Zhang, Richard Yuanzhe Pang, Clara Vania, Katharina Kann, Samuel R. Bowman</span>
<br>
<span style="line-height:170%"> In <i>Proceedings of ACL 2020</i> </span>
<br>  
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/2005.00628.pdf" style="color: #757575; text-decoration: none">paper</a>] [<a href="./research/#exactline-acl20-b" style="color: #757575; text-decoration: none">abstract</a>] [<a href="../misc-files/bibs/pruksachatkun2020intermediate.txt" style="color: #757575; text-decoration: none">bibtex</a>] </span>


<br>


<!-- <font size="3"> -->
<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/1810.11878" style="font-size: 11pt; color: #245ED2; text-decoration: none"> Unsupervised Evaluation Metrics and Learning Criteria for Non-Parallel Textual Transfer </a> <br> </span>
<span style="line-height:170%"> Richard Yuanzhe Pang, Kevin Gimpel </span>
<br>
<span style="line-height:170%"> In <i>Proceedings of EMNLP 2019 Workshop on Neural Generation and Translation (WNGT) </i> </span>
<br>
<span style="line-height:195%; font-size: 9pt"> tl;dr: proposing more dimensions for textual transfer evaluation metrics, and losses that target them </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/1810.11878.pdf" style="color: #245ED2; text-decoration: none">paper</a>] [<a href="https://arxiv.org/pdf/1810.11878.pdf#page=11" style="color: #245ED2; text-decoration: none">supplementals</a>] [<a href="./research/#exactline-wngt19-a" style="color: #245ED2; text-decoration: none">abstract</a>] [<a href="../misc-files/pang+gimpel-textual-transfer-poster.pdf" style="color: #245ED2; text-decoration: none">poster</a>] [<a href="../misc-files/bibs/pang2018unsupervised.txt" style="color: #245ED2; text-decoration: none">bibtex</a>] </span>


<br>


<p class="small">
<span style="font-weight:500"> <a href="https://arxiv.org/abs/1910.03747" style="font-size: 11pt; color: #245ED2; text-decoration: none"> The Daunting Task of Real-World Textual Style Transfer Auto-Evaluation </a> <br> </span>
<span style="line-height:170%"> Richard Yuanzhe Pang</span>
<br>
<span style="line-height:170%"> Extended abstract in <i>EMNLP 2019 Workshop on Neural Generation and Translation (WNGT)</i>; abstract in <i>Proceedings of the Workshop on Noisy User-generated Text (W-NUT)</i> 
<br>
<span style="line-height:195%; font-size: 9pt"> tl;dr: an opinion piece arguing that the research on textual style transfer and its evaluation are going astray </span>
<br>
<span style="line-height:170%"> [<a href="https://arxiv.org/pdf/1910.03747.pdf" style="color: #245ED2; text-decoration: none">paper</a>] [<a href="./research/#exactline-wngt19-b" style="color: #245ED2; text-decoration: none">abstract</a>] [<a href="../misc-files/pang-textual-transfer-problem-poster.pdf" style="color: #245ED2; text-decoration: none">poster</a>] [<a href="../misc-files/bibs/pang2019daunting.txt" style="color: #245ED2; text-decoration: none">bibtex</a>] </span>




<br><br>


<p class="small">

More info: [<a href="https://scholar.google.com/citations?hl=en&user=vg_IkckAAAAJ" style="color: #4C8BF5; text-decoration: none" target="_blank">google scholar</a>] [<a href="https://www.semanticscholar.org/author/Richard-Yuanzhe-Pang/46230016?sort=pub-date" style="color: #4C8BF5; text-decoration: none" target="_blank">semantic scholar</a>] [<a href="https://dblp.org/pid/250/9059.html" style="color: #4C8BF5; text-decoration: none" target="_blank">dblp</a>] [<a href="../misc-files/abbreviations.txt" style="color: #4C8BF5; text-decoration: none" target="_blank">abbreviations</a>] [<a href="https://twitter.com/yzpang_" style="color: #4C8BF5; text-decoration: none" target="_blank">twitter/x</a>]








<h3 style="font-weight: 500">Other writings</h3>
<hr>


<p class="small">
<span style="font-weight:500"> <a href="https://cs.nyu.edu/media/publications/pang-dissertation-20240708.pdf" style="font-size: 11pt; color: #245ED2; text-decoration: none"> Learning from Rewards in Text Generation </a> </span> <span style="line-height:170%"> [<a href="https://cs.nyu.edu/media/publications/pang-dissertation-20240708.pdf" style="color: #245ED2; text-decoration: none">pdf</a>] [<a href="https://cs.nyu.edu/media/publications/pang-dissertation-20240708.pdf#page=10" style="color: #245ED2; text-decoration: none">table of contents</a>] <br> </span>
<span style="line-height:170%"> Ph.D. dissertation (committee members: Drs. He He, Kyunghyun Cho, Jason Weston, Mengye Ren, and Ankur P. Parikh) </span>

<p class="small">
<span style="font-weight:500"> <a href="../misc-files/pang-gold-discussion-2022-06.pdf" style="font-size: 11pt; color: #245ED2; text-decoration: none"> Discussion of GOLD </a> </span> <span style="line-height:170%"> [<a href="../misc-files/pang-gold-discussion-2022-06.pdf" style="color: #245ED2; text-decoration: none">pdf</a>] [<a href="https://cs.nyu.edu/media/publications/pang-dissertation-20240708.pdf#page=77" style="color: #245ED2; text-decoration: none">integrated in dissertation page ~55</a>] <br> </span>
<span style="line-height:170%"> June 2022 </span>
<br>
<span style="line-height:195%; font-size: 9pt"> tl;dr: GOLD does not maximize the expected reward. It maximizes the expected reward of training examples only. </span>







<h3 style="font-weight: 500">More research activities</h3>
<hr>


<p class="small">
<!-- <font size="3"> -->

<span style="line-height:170%"> <u>As an area chair / action editor</u> </span>
<ul class="small" style="margin-left: 16px;">
<li> ACL 2023 (summarization), ACL Rolling Review (02,04,06,10/2024; areas: generation, language modeling, QA, dialogue, resource & eval) </li>
</ul>


<p class="small">

<span style="line-height:170%"> <u>As a reviewer / program committee member</u> </span>
<ul class="small" style="margin-left: 16px;">
<li> Top ML/NLP venues: AAAI (2023), ACL Rolling Review (10,11/2021; 01,02,12/2022; 02,06,08,10,12/2023), ACL (2021), Conference on Language Modeling (COLM; 2024), EMNLP (2021, 2022), ICLR (2022, 2023, 2024, 2025), ICLR blog post track (2022), ICML (2022, 2023, 2024), NeurIPS (2021 — top 8% reviewer, 2022, 2023 — top 10% reviewer, 2025), Transactions on Machine Learning Research (TMLR; 2022, 2023, 2024) [<a href="../misc-files/abbreviations.txt" style="color: #757575; text-decoration: none" target="_blank">abbreviations</a>] </li>
<li> Workshops: Novel Ideas in Learning-to-Learn through Interaction (NILLI at EMNLP 2021 and EMNLP 2022), Efficient Benchmarking in NLP (NLP Power at ACL 2022), Interactive Learning for NLP (InterNLP at NeurIPS 2022), Multilingual Representation Learning (MRL at EMNLP 2023), Mathematical and Empirical Understanding of Foundation Models (ME-FoMo at ICLR 2024)</li>
<li> Other events: Mid-Atlantic Student Colloquium on Speech, Language, and Learning (2022, 2023), Inverse Scaling Prize (2023; <a href="https://github.com/inverse-scaling/prize" style="color: #4d4d4d">github</a>, <a href="https://arxiv.org/pdf/2306.09479.pdf" style="color: #4d4d4d">report</a>) </li>
</ul>









<h3 style="font-weight: 500">Teaching</h3>
<hr>

<p class="small">
<!-- <font size="3"> -->
<span style="line-height:200%"> <u>External</u> </span>
<ul class="small" style="margin-left: 16px;">
<li> May 2022, <i>Teaching Assistant / Lab Instructor</i> (virtual), African Masters of Machine Intelligence (course: Deep Learning for NLP by Prof. Kyunghyun Cho and Prof. Duygu Ataman) [<a href="https://aimsammi.org/" style="color: #4d4d4d">AMMI site</a>] <br> </li>
</ul>


<p class="small">
<!-- <font size="3"> -->
<span style="line-height:200%"> <u>At New York University</u> </span>
<ul class="small" style="margin-left: 16px;">
<li> May 2023, <i>Co-organizer</i>, NYU AI School 2023 (in-person) [<a href="https://nyu-mll.github.io/nyu-ai-school-2023/" style="color: #4d4d4d">site</a>] <br> </li> 
<li> Spring 2022, <i>Section Leader / Teaching Assistant</i> (in-person), DS-GA 1012 / LING-GA 1012: Natural Language Understanding and Computational Semantics (Bowman; graduate-level) [<a href="https://docs.google.com/document/d/e/2PACX-1vRydPvLp9tNw1-45pp6IIl-jppX-tUfu0TQDVXRAiGA3CjIuJzBTzJo7cerQV08K8FqfUOYHBCPAggx/pub" style="color: #4d4d4d">syllabus</a>] <br> </li>
<li> January 2022, <i>Co-instructor / Co-organizer</i>, NYU AI School 2022 (virtual) [<a href="https://nyu-mll.github.io/nyu-ai-school-2022/" style="color: #4d4d4d">site</a>] <br> </li> 
<li> Fall 2020, <i>Section Leader</i> (in-person), DS-GA 1008: Deep Learning (Cho, LeCun; graduate-level) [<a href="https://kyunghyuncho.me/courses/" style="color: #4d4d4d">syllabus</a>] [<a href="https://kyunghyuncho.me/a-few-qa-from-the-course/" style="color: #4d4d4d">Cho's QA blog post</a>] <br> </li> 
</ul>


<p class="small">
<span style="line-height:200%"> <u>At the University of Chicago</u> </span>
<ul class="small" style="margin-left: 16px;">
<li> Spring 2017, <i>Course Assistant</i>, MATH 15910: Intro to Proofs in Analysis<br> </li>
<li> Winter 2017, <i>Course Assistant</i>, MATH 15910: Intro to Proofs in Analysis [<a href="../misc-files/math-15910-winter-2017-sol.html" style="color: #4d4d4d">sol]</a><br> </li>
<li> Winter 2017, <i>Grader</i>, CMSC 15200: Intro to Computer Science II<br> </li>
<li> Autumn 2016, <i>Teaching Assistant</i>, MATH 15300: Calculus III<br> </li>
</ul>

<!-- </font> -->
<p>








<h3 style="font-weight: 500">Presentations</h3>
<hr>





<p class="small">
<span style="line-height:170%"> <u> Selected presentations </u> </span>


<ul class="small" style="margin-left: 16px;">


<li> Talk on learning from rewards in text generation & long-context benchmarks; Nvidia; January 2024 </li> 

<li> Talk on <i>Leveraging Implicit Feedback from Deployment Data in Dialogue</i>; Meta reading group; August 2023 </li> 

<li> Talk on <i>QuALITY: Question Answering with Long Input Texts, Yes!</i> and <i> SQuALITY: Building a Long-Document Summarization Dataset the Hard Way</i>; Meta AI reading group in New York; October 2022 </li> 

<li> Talk titled <i>QuALITY: Question Answering with Long Input Texts, Yes!</i>; NAACL 2022 in Seattle; July 2022 [<a href="https://www.youtube.com/watch?v=WAhSW5iP8iw" style="color: #22789D; text-decoration: none">live talk</a>] </li> 

<li> Talk on <i>QuALITY: Question Answering with Long Input Texts, Yes!</i> in NYU's undergraduate course LING-UA 52 / DS-UA 203 ML for Language Understanding; March 2022 </li> 

<li> Talk on RL in text generation and <i>Text Generation by Learning from Demonstrations</i> in NYU's graduate course DS/LING-GA 1012 Natural Language Understanding; March 2022 </li> 

<li> Talk on question answering data collection (QuALITY, SQuALITY, etc.); Apple; December 2021 </li>

<li> Talk titled <i>Text Generation by Learning from Demonstrations</i>; Samsung workshop; June 2021 [based on <a href="../misc-files/pang+he-gold-slides.pdf" style="color: #245ED2; text-decoration: none">this slide deck</a>] </li>

<li> Talk on structured prediction (specifically, inference networks and structured prediction energy networks); Bank of New York Mellon; September 2020 [based on <a href="../misc-files/pang-spen-infnet-joint-training-slides.pdf" style="color: #245ED2; text-decoration: none">this slide deck</a>] </li>   

<li> Talk titled <i>Text Generation by Offline RL</i>; Google Research New York; July 2020 </li>

<li> Poster presentation on <i>Learning Criteria and Evaluation Metrics for Textual Transfer between Non-Parallel Corpora</i>; NAACL 2019 NeuralGen workshop in Minneapolis; June 2019 </li>

<li> Talk titled <i>Learning Approximate Inference Networks and Structured Prediction Energy Networks</i>; Midwest Speech and Language Days (MSLD) 2019 in Chicago; May 2019 </li>

<li> Poster presentation on <i>Learning Criteria and Evaluation Metrics for Textual Transfer between Non-Parallel Corpora</i>; UChicago STEM Research Symposium in Chicago; October 2018 </li>


</ul>



<p class="small">
<span style="line-height:170%"> <u> Other conference presentations with associated proceeding papers </u> </span>

<ul class="small" style="margin-left: 16px;">

Please email for full CV.

<!-- <li> 5-min talk and poster presentation on <i>Text Generation by Learning from Demonstrations</i>; ICLR 2021; May 2021 [<a href="../misc-files/pang+he-gold-poster.pdf" style="color: #245ED2; text-decoration: none">poster</a>]</li>

<li> Poster presentation and lightning talk on <i>The Daunting Task of Real-World Textual Style Transfer Auto-Evaluation</i>; EMNLP 2019 WNGT workshop (poster) and W-NUT workshop (lightning talk) in Hong Kong, China; November 2019 [<a href="../misc-files/pang-textual-transfer-problem-poster.pdf" style="color: #245ED2; text-decoration: none">poster</a>]</li>


<li> Poster presentation on <i>Unsupervised Evaluation Metrics and Learning Criteria for Non-Parallel Textual Transfer</i>; EMNLP 2019 WNGT workshop in Hong Kong, China; November 2019 [<a href="../misc-files/pang+gimpel-textual-transfer-poster.pdf" style="color: #245ED2; text-decoration: none">poster</a>]</li>
 -->

</ul>









<!-- 
<h3 style="font-weight: 500">Relevant Coursework</h3>
<hr>

<p class="xsmall">
<span style="line-height:300%"> <u> At the University of Chicago (2015-2019) </u> </span>
<br>
CMSC 27230 - Honors Theory of Algorithms<br>
CMSC 25025 / STAT 37601 - Machine Learning and Large-Scale Data Analysis (grad level, Lafferty)<br>
CMSC 35400 / STAT 37710 - Machine Learning (grad level, Kondor)<br>
TTIC 31020 - Statistical Machine Learning (grad level, Shakhnarovich)<br>
TTIC 31190 - Natural Language Processing (grad level, Gimpel)<br>
TTIC 41000 - Spectral Techniques (grad level, Stratos)<br>
MATH 20300-20500 - Accelerated Real Analysis I, II, III<br>
MATH 20250, 25400-25500 - Abstract Linear Algebra; Abstract Algebra I, II<br>
BIOS 10602-10603 - Multiscale Modeling of Biological Systems I, II (computational biology)
 -->






<!-- 
<p>
 -->

<!-- <h3 style="font-weight: 500">Miscellaneous</h3>
<hr>

<p class="small">
I <a href="/writings/" style="color: #008016">write</a>. 
</p> -->




<br><br>



<p class="noindent" style="font-size: 11.5pt; margin-left: 0px; text-decoration: none">
<!-- <font size="3"> -->

Last updated: January 27, 2026. 

<!-- </font> -->
</p>










</body>

{% for post in paginator.posts %}
  {% include archive-single.html %}
{% endfor %}

{% include paginator.html %}
